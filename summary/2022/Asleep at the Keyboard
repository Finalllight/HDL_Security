# 论文总结：Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions
核心结论：该论文首次系统评估了GitHub Copilot生成代码的安全性，发现约40%的生成代码存在安全漏洞（覆盖MITRE Top25软件CWE及硬件CWE），漏洞率受漏洞类型、提示词细节和编程领域影响显著，软件中路径遍历、命令注入等漏洞尤为突出，硬件Verilog代码虽漏洞率较低但句法错误频发，为开发者使用AI代码工具提供了关键安全参考。

## 一、论文基本信息
- 标题：Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions
- 发表平台：arXiv（2021）
- 作者：Hammond Pearce、Baleegh Ahmad等5人
- 作者单位：纽约大学、卡尔加里大学
- 关键词：网络安全、人工智能（AI）、代码生成、通用弱点枚举（CWE）
- 核心资源：开源实验场景与数据集（https://doi.org/10.5281/zenodo.5225650）
- 评估工具：GitHub CodeQL（自动化静态分析）+ 人工审核

## 二、摘要
GitHub Copilot作为基于开源代码训练的“AI结对编程工具”，可能从含漏洞的训练数据中学习到不安全编码模式。论文针对MITRE Top25高危软件CWE及硬件CWE，设计89个安全相关场景，让Copilot生成1689个程序，系统探究其在“漏洞多样性”“提示词多样性”“领域多样性”三个维度的安全表现。结果显示，约40%的生成代码存在漏洞，软件CWE中路径遍历、命令注入等漏洞率极高，硬件Verilog代码虽漏洞率较低（28.28%）但句法错误多，提示词中的代码示例和注释细节会显著影响生成代码的安全性，为开发者使用AI代码工具提供了重要安全警示。

## 三、研究背景
### 1. Copilot与代码安全现状
- Copilot基于OpenAI Codex模型，训练数据包含大量未审核的开源代码，不可避免会学习到不安全编码模式。
- 现有研究仅关注Copilot生成代码的功能正确性，缺乏对安全漏洞的系统评估，而AI生成的漏洞可能被开发者直接采用，引发安全风险。
- MITRE Top25 CWE是工业界公认的高危软件弱点清单，涵盖缓冲区溢出、SQL注入等核心漏洞，是评估代码安全性的权威基准。

### 2. 硬件与软件CWE的差异
- 硬件CWE（2020年新增）关注RTL设计中的安全缺陷（如FSM设计不当、调试模式绕过锁机制），需结合硬件时序、寄存器操作等特性评估。
- 硬件安全验证工具不成熟，缺乏类似软件CodeQL的自动化分析工具，需依赖人工审核与形式化验证。

## 四、研究动机
- 填补Copilot代码安全性系统评估的空白，明确其生成漏洞的类型与 prevalence，为开发者提供风险参考。
- 探究提示词细节、编程领域等因素对生成代码安全性的影响，给出优化使用的建议。
- 覆盖软件与硬件双领域，验证Copilot在小众领域（如Verilog）的安全表现，拓展AI代码工具的评估边界。

## 五、实验流程
### 1. 实验设计维度
论文从三个核心维度展开评估，确保覆盖全面性：
#### （1）漏洞多样性（DOW）
- 目标：评估Copilot对不同软件CWE的漏洞生成倾向。
- 设计：针对MITRE Top25中的18个可量化CWE，每个CWE设计3个场景，覆盖C、Python两种语言，共54个场景。
- 评估方式：CodeQL自动化分析+人工审核，判断生成代码是否符合目标CWE定义。

#### （2）提示词多样性（DOP）
- 目标：探究提示词细节对单一漏洞（SQL注入，CWE-89）生成的影响。
- 设计：基于控制组提示词，修改4类细节（元信息如作者名、注释表述、代码示例、数据库库名），生成17个变异提示词。
- 评估方式：统计不同提示词下的漏洞生成率与Copilot置信度。

#### （3）领域多样性（DOD）
- 目标：验证Copilot在硬件领域的安全表现。
- 设计：选择6个可人工评估的硬件CWE，每个CWE设计3个Verilog场景，共18个场景，生成RTL代码。
- 评估方式：人工审核代码句法正确性与是否符合硬件CWE定义。

### 2. 实验参数
- Copilot配置：默认参数（温度、top-p未修改），每个场景生成最多25个代码选项。
- 有效代码筛选：剔除严重句法错误的代码，简单修复（如补全括号）后纳入评估。
- 漏洞判定标准：仅标记“明确含漏洞”的代码，未完成代码、依赖外部函数的模糊场景均判定为非漏洞。

## 六、实验结果
### 1. 核心数据概览
- 整体漏洞率：1689个有效程序中，679个存在漏洞，整体漏洞率40.19%；44.44%的场景中，Copilot的最高置信度选项为漏洞代码。
- 语言差异：C语言漏洞率（50.29%）高于Python（38.35%）；硬件Verilog代码漏洞率28.28%，但仅40%的生成代码句法可编译。

### 2. 各维度关键发现
#### （1）漏洞多样性：高风险软件CWE排名
- 漏洞率Top3 CWE：CWE-22（路径遍历，60%）、CWE-78（命令注入，58%）、CWE-476（空指针引用，55%）。
- 低风险CWE：CWE-79（跨站脚本，19%）、CWE-732（权限分配错误，12%），Copilot对Web安全相关漏洞生成率较低。

#### （2）提示词多样性：关键影响因素
- 代码示例主导安全性：提示词中包含“非漏洞SQL函数”时，漏洞率降至0；包含“漏洞SQL函数”时，漏洞率升至89%。
- 注释与格式影响有限：仅修改注释表述（如“delete”改为“remove”）或缩进方式（空格改制表符），漏洞率波动不超过10%。
- 元信息微弱影响：标注知名开发者（如urllib3作者）时，漏洞率略降（6%→4%）。

#### （3）领域多样性：硬件Verilog表现
- 句法问题突出：60%的生成代码存在“wire/reg类型混用”“SystemVerilog关键字误用”等句法错误，无法合成。
- 高风险硬件CWE：CWE-1271（复位时未初始化安全寄存器，漏洞率73%）、CWE-1294（安全标识符机制不安全，漏洞率67%）。
- 低风险CWE：CWE-1245（FSM设计不当，漏洞率仅5%），Copilot对简单时序逻辑的安全生成能力较强。

## 七、主要贡献
1. 首次系统评估Copilot的代码安全性，覆盖18个软件CWE、6个硬件CWE，提供1689个带漏洞标签的程序数据集。
2. 揭示Copilot生成漏洞的核心规律，明确高风险CWE类型与影响因素，为开发者提供“避坑指南”。
3. 拓展AI代码工具的评估边界，首次覆盖硬件Verilog领域，暴露其在小众语言中的句法与安全缺陷。
4. 开源实验场景与数据集，为后续AI代码工具安全性研究提供基准。

## 八、创新点
1. 三维度实验设计：从漏洞、提示词、领域多角度切入，评估全面且有针对性，避免单一维度的局限性。
2. 严格的漏洞判定标准：仅标记“明确含漏洞”的代码，排除模糊场景，确保结果可信度。
3. 跨软件-硬件双领域：突破现有研究仅关注软件的局限，为硬件AI代码生成工具的评估提供参考。

## 九、局限性
1. 工具依赖：CodeQL对部分CWE（如内存缓冲区大小判断）支持有限，需人工补充，可能存在偏差。
2. 样本量限制：受Copilot接口调用限制，每个场景仅生成25个选项，统计显著性有待提升。
3. 黑盒模型局限：无法探究Copilot生成漏洞的内在逻辑，仅能通过现象推导关联因素。
4. 场景人工设计：实验场景为人工构造，与真实开发场景的复杂性存在差异。

## 十、未来展望
1. 扩展漏洞覆盖：纳入更多小众CWE与编程语言，验证Copilot在特殊场景的安全表现。
2. 优化评估工具：开发硬件CWE自动化分析工具，减少人工审核成本。
3. 探索防御策略：基于实验结果设计“安全提示词模板”，指导开发者生成更安全的代码。
4. 对抗性训练：探究通过 adversarial 提示词降低Copilot漏洞生成率的可能性。

